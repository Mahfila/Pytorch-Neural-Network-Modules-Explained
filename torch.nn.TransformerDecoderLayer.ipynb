{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2668a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f2cee0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 2\n",
    "n_head = 1\n",
    "query = torch.tensor([[[0.7204, 0.0731],\n",
    "          [0.9699, 0.1078],\n",
    "          [0.8829, 0.4132]]])\n",
    "\n",
    "key = query.clone()\n",
    "value = query.clone()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239b9de",
   "metadata": {},
   "source": [
    "### Getting the memory (key, value) from the Encoder Layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7aef8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_layer = nn.TransformerEncoderLayer(d_model=E, nhead=1,batch_first=True,dropout=0,dim_feedforward=2)\n",
    "zeros_tensor = torch.nn.Parameter(torch.zeros(2))\n",
    "encoder_layer.linear1.bias = zeros_tensor\n",
    "encoder_layer.linear2.bias = zeros_tensor\n",
    "encoder_output= encoder_layer(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dac0348f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac5ea76",
   "metadata": {},
   "source": [
    "### Defining the Decorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c02277c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_layer = nn.TransformerDecoderLayer(d_model=E, nhead=1,batch_first=True,dropout=0,dim_feedforward=2)\n",
    "zeros_tensor = torch.nn.Parameter(torch.zeros(2))\n",
    "decoder_layer.linear1.bias = zeros_tensor\n",
    "decoder_layer.linear2.bias = zeros_tensor\n",
    "decoder_output = decoder_layer(query, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fdb84ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0700,  0.2625],\n",
       "        [ 0.6664,  0.3238],\n",
       "        [ 0.5044, -0.6509],\n",
       "        [-0.6687, -0.6628],\n",
       "        [-0.5943, -0.6812],\n",
       "        [ 0.4039, -0.2455]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_layer.state_dict()['self_attn.in_proj_weight']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bba0f4",
   "metadata": {},
   "source": [
    "### MHA One  and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f49f1241",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### SA\n",
    "weight = decoder_layer.state_dict()['self_attn.in_proj_weight']\n",
    "q,k,v =  query.matmul(weight.t()).chunk(3, dim=-1)\n",
    "v = v.reshape(3,2)\n",
    "q = q.reshape(3,2)\n",
    "k = k.reshape(3,2)\n",
    "q = q / math.sqrt(E)\n",
    "attn1 = torch.matmul(q,k.T)\n",
    "m = nn.Softmax(dim=-1)\n",
    "attn = m(attn1)\n",
    "output = torch.matmul(attn, v)\n",
    "output = output.reshape((3,2))\n",
    "out_proj = decoder_layer.state_dict()['self_attn.out_proj.weight']\n",
    "output_last = output.matmul(out_proj.t())\n",
    "x = key.reshape((3,2)) + output_last\n",
    "\n",
    "###### NORM\n",
    "copied_data = x.clone()\n",
    "layer_norm1 = nn.LayerNorm(2)\n",
    "x = layer_norm1(x)\n",
    "\n",
    "# x is going to be the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03dba0b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0170, -0.4485, -0.3418, -0.8304,  0.6771, -0.0114],\n",
       "        [ 0.7792, -0.5596,  0.4939,  0.7070, -0.4128,  0.2273]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_layer.state_dict()['multihead_attn.in_proj_weight'].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94135a14",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0170, -0.4485],\n",
       "         [ 0.7792, -0.5596]]),\n",
       " tensor([[-0.3418, -0.8304],\n",
       "         [ 0.4939,  0.7070]]),\n",
       " tensor([[ 0.6771, -0.0114],\n",
       "         [-0.4128,  0.2273]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " decoder_layer.state_dict()['multihead_attn.in_proj_weight'].t().chunk(3, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e258afa3",
   "metadata": {},
   "source": [
    "### MHA two  and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eae83308",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MHA\n",
    "my_memory = encoder_output.clone()\n",
    "weight = decoder_layer.state_dict()['multihead_attn.in_proj_weight'].t().chunk(3, dim=-1)\n",
    "# q is from above , k and v are the encoder outputs\n",
    "qw = weight[0]\n",
    "kw = weight[1]\n",
    "vw = weight[2]\n",
    "q = torch.matmul(x,qw)\n",
    "k = torch.matmul(my_memory,kw)\n",
    "v = torch.matmul(my_memory,vw)\n",
    "q = q.reshape(3,2)\n",
    "k = k.reshape(3,2)\n",
    "v = v.reshape(3,2)  ##\n",
    "q = q / math.sqrt(E)\n",
    "attn1 = torch.matmul(q,k.T)\n",
    "m = nn.Softmax(dim=-1)\n",
    "my_attn_output_weights = m(attn1)\n",
    "output = torch.matmul(my_attn_output_weights, v)\n",
    "output = output.reshape((3,2))\n",
    "out_proj = decoder_layer.state_dict()['multihead_attn.out_proj.weight']\n",
    "my_output = output.matmul(out_proj.t())\n",
    "x = x + my_output\n",
    "\n",
    "#### NORM\n",
    "copied_data = x.clone()\n",
    "layer_norm1 = nn.LayerNorm(2)\n",
    "x = layer_norm1(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be346ed4",
   "metadata": {},
   "source": [
    "### Multiple FCC Layers and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19b4b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FC\n",
    "b = x.squeeze()\n",
    "linear1 = torch.matmul(b,decoder_layer.state_dict()['linear1.weight'].T)\n",
    "m = nn.ReLU()\n",
    "linear1_relu = m(linear1)\n",
    "linear2 = torch.matmul(linear1_relu,decoder_layer.state_dict()['linear2.weight'].T)\n",
    "x = x + linear2\n",
    "\n",
    "layer_norm2 = nn.LayerNorm(2)\n",
    "x = layer_norm2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19b4c181",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000],\n",
       "         [ 1.0000, -1.0000]]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4532a92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -1.0000],\n",
       "        [ 1.0000, -1.0000],\n",
       "        [ 1.0000, -1.0000]], grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x  #out result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20369dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
