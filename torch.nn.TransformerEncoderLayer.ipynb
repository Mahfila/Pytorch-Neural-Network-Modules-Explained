{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f273fe07",
   "metadata": {},
   "source": [
    "## Encoder Formular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74c8623",
   "metadata": {},
   "source": [
    "### x = self.norm1(x + self._sa_block(x, src_mask, src_key_padding_mask))\n",
    "### x = self.norm2(x + self._ff_block(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d73725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fe92fa664d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "torch.manual_seed(1773) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f4fce",
   "metadata": {},
   "source": [
    "### Embedding and Positional Encoding and Setting the Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9b3b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = 2\n",
    "n_head = 1\n",
    "embedding = torch.tensor([[1.1,-0.5],[0.6,0.9],[0.8,0.6]])\n",
    "positional_embedding = torch.tensor([[0,1],[0.84,0.54],[0.90,-0.41]])\n",
    "query = (embedding+ positional_embedding).reshape((1,3,2))\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=E, nhead=1,batch_first=True,dropout=0,dim_feedforward=2)\n",
    "zeros_tensor = torch.nn.Parameter(torch.zeros(2))\n",
    "encoder_layer.linear1.bias = zeros_tensor\n",
    "encoder_layer.linear2.bias = zeros_tensor\n",
    "out = encoder_layer(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2b0d86",
   "metadata": {},
   "source": [
    "### Self Attention "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed2f8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.tensor([[[0.7204, 0.0731],\n",
    "          [0.9699, 0.1078],\n",
    "          [0.8829, 0.4132]]])\n",
    "\n",
    "\n",
    "key = query\n",
    "value = query\n",
    "weight = encoder_layer.state_dict()['self_attn.in_proj_weight']\n",
    "\n",
    "q,k, v =  query.matmul(weight.t()).chunk(3, dim=-1)\n",
    "v = v.reshape(3,2)\n",
    "q = q.reshape(3,2)\n",
    "k = k.reshape(3,2)\n",
    "q = q / math.sqrt(E)\n",
    "attn1 = torch.matmul(q,k.T)\n",
    "m = nn.Softmax(dim=-1)\n",
    "attn = m(attn1)\n",
    "output = torch.matmul(attn, v)\n",
    "output = output.reshape((3,2))\n",
    "out_proj = encoder_layer.state_dict()['self_attn.out_proj.weight']\n",
    "output_last = output.matmul(out_proj.t())\n",
    "x = key.reshape((3,2)) + output_last"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb05ea",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6068414",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_data = x.clone()\n",
    "layer_norm1 = nn.LayerNorm(2)\n",
    "x = layer_norm1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ae9b3b",
   "metadata": {},
   "source": [
    "## Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f1ca8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = x.squeeze()\n",
    "linear1 = torch.matmul(b,encoder_layer.state_dict()['linear1.weight'].T)\n",
    "m = nn.ReLU()\n",
    "linear1_relu = m(linear1)\n",
    "linear2 = torch.matmul(linear1_relu,encoder_layer.state_dict()['linear2.weight'].T)\n",
    "x = x + linear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edc1c9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = x.squeeze()\n",
    "linear1 = torch.matmul(b,encoder_layer.state_dict()['linear1.weight'].T)\n",
    "m = nn.ReLU()\n",
    "linear1_relu = m(linear1)\n",
    "linear2 = torch.matmul(linear1_relu,encoder_layer.state_dict()['linear2.weight'].T)\n",
    "x = x + linear2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ba57b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_data2 = x.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1b44ca0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0920, -0.2562],\n",
       "        [ 0.0920, -0.2562],\n",
       "        [ 0.0920, -0.2562]], grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copied_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a1c0c",
   "metadata": {},
   "source": [
    "## Normalization Two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfab5837",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm2 = nn.LayerNorm(2)\n",
    "x = layer_norm2(x)\n",
    "data = copied_data\n",
    "data = copied_data2\n",
    "mean = data.mean(dim=1,keepdim=True)\n",
    "var =torch.sum((data-mean) *(data-mean),dim=1)/2\n",
    "var_sqrt = torch.sqrt(var).reshape((3,1))\n",
    "subs = (data - mean)\n",
    "final_out = subs / var_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bca50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1., -1.],\n",
       "        [ 1., -1.],\n",
       "        [ 1., -1.]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e99bdaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0527,  0.7927],\n",
      "        [ 0.0792, -0.1440],\n",
      "        [ 0.3668,  0.4421],\n",
      "        [ 0.4672,  0.0248],\n",
      "        [ 0.6537, -0.3068],\n",
      "        [ 0.5988, -0.0251]])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "encoder_layer = nn.TransformerEncoderLayer(d_model=2, nhead=1,batch_first=True,dropout=0,dim_feedforward=2)\n",
    "attention_weights = encoder_layer.state_dict()['self_attn.in_proj_weight']\n",
    "print(attention_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ec3fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
